{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "muuvOqYxQ0s8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_f1_score(conf_matrix):\n",
        "    # Extract True Positives (TP)\n",
        "    TP = np.diag(conf_matrix)  # Extract diagonal elements (TP for each class)\n",
        "\n",
        "    # Compute False Positives (FP) by summing columns and subtracting TP\n",
        "    FP = np.sum(conf_matrix, axis=0) - TP\n",
        "\n",
        "    # Compute False Negatives (FN) by summing rows and subtracting TP\n",
        "    FN = np.sum(conf_matrix, axis=1) - TP\n",
        "\n",
        "    # Compute Precision and Recall (Adding 1e-9 to avoid division by zero)\n",
        "    precision = TP / (TP + FP + 1e-9)\n",
        "    recall = TP / (TP + FN + 1e-9)\n",
        "\n",
        "    # Compute F1 Score for each class\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
        "\n",
        "    return f1_score\n",
        "\n"
      ],
      "metadata": {
        "id": "jL0aJOyOQ5MC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample confusion matrix for a 2-class problem\n",
        "conf_matrix = np.array([[50, 10],  # Class 0: 50 TP, 10 FN\n",
        "                        [5, 35]])  # Class 1: 5 FP, 35 TN\n",
        "\n",
        "# Compute F1 scores\n",
        "f1_scores = calculate_f1_score(conf_matrix)\n",
        "\n",
        "# Print results\n",
        "print(\"F1 Scores for each class:\", f1_scores)\n",
        "print(\"Macro F1 Score:\", np.mean(f1_scores))  # Average F1 score across classes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8riI6wffREBU",
        "outputId": "f61e45e2-a5e0-4163-e36a-bbee68088019"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Scores for each class: [0.86956522 0.82352941]\n",
            "Macro F1 Score: 0.8465473140620927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qcZHD87nRGV7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}