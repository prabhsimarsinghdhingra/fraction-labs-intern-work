{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#  necessary libraries\n",
        "!pip install pandas sqlalchemy openpyxl pymysql\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "#  sample CSV data\n",
        "csv_data = pd.DataFrame({\n",
        "    'Train Number': [12345, 67890, 13579],\n",
        "    'Train Name': ['Rajdhani Express', 'Shatabdi Express', 'Duronto Express'],\n",
        "    'Departure Time': ['06:00', '08:30', '22:15'],\n",
        "    'Arrival Time': ['18:00', '14:00', '06:45'],\n",
        "    'Source': ['Delhi', 'Mumbai', 'Kolkata'],\n",
        "    'Destination': ['Mumbai', 'Chennai', 'Delhi']\n",
        "})\n",
        "csv_data.to_csv(\"train_schedule_zone1.csv\", index=False)\n",
        "\n",
        "#  sample Excel data\n",
        "excel_data = pd.DataFrame({\n",
        "    'Train Number': [24680, 11223, 44556],\n",
        "    'Train Name': ['Garib Rath', 'Jan Shatabdi', 'Tejas Express'],\n",
        "    'Departure Time': ['09:15', '11:45', '17:30'],\n",
        "    'Arrival Time': ['21:30', '19:20', '23:50'],\n",
        "    'Source': ['Bangalore', 'Pune', 'Hyderabad'],\n",
        "    'Destination': ['Kolkata', 'Delhi', 'Mumbai']\n",
        "})\n",
        "excel_data.to_excel(\"train_schedule_zone2.xlsx\", index=False)\n",
        "\n",
        "#  sample SQL database\n",
        "engine = create_engine(\"sqlite:///train_schedule.db\")\n",
        "sql_data = pd.DataFrame({\n",
        "    'Train Number': [55678, 99887, 33445],\n",
        "    'Train Name': ['Vande Bharat', 'Humsafar Express', 'Mahamana Express'],\n",
        "    'Departure Time': ['05:45', '12:10', '19:55'],\n",
        "    'Arrival Time': ['15:20', '22:40', '04:30'],\n",
        "    'Source': ['Jaipur', 'Ahmedabad', 'Chennai'],\n",
        "    'Destination': ['Lucknow', 'Bhopal', 'Varanasi']\n",
        "})\n",
        "sql_data.to_sql(\"train_schedule_zone3\", con=engine, if_exists=\"replace\", index=False)\n",
        "\n",
        "# Function to read CSV files\n",
        "def read_csv(file_path):\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "# Function to read Excel files\n",
        "def read_excel(file_path):\n",
        "    return pd.read_excel(file_path)\n",
        "\n",
        "# Function to read SQL database\n",
        "def read_sql(db_connection_string, table_name):\n",
        "    engine = create_engine(db_connection_string)\n",
        "    return pd.read_sql(f\"SELECT * FROM {table_name}\", con=engine)\n",
        "\n",
        "# Function to clean and standardize data\n",
        "def clean_data(df):\n",
        "    df.columns = df.columns.str.lower().str.replace(\" \", \"_\")  # Standardize column names\n",
        "    df.drop_duplicates(inplace=True)  # Remove duplicate entries\n",
        "    df.dropna(inplace=True)  # Drop missing values\n",
        "    if 'train_number' in df.columns:\n",
        "        df['train_number'] = df['train_number'].astype(str).str.zfill(5)  # Standardize train number format\n",
        "    return df\n",
        "\n",
        "# Function to merge datasets\n",
        "def merge_datasets(dfs):\n",
        "    return pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Load Data\n",
        "csv_data = read_csv(\"train_schedule_zone1.csv\")\n",
        "excel_data = read_excel(\"train_schedule_zone2.xlsx\")\n",
        "sql_data = read_sql(\"sqlite:///train_schedule.db\", \"train_schedule_zone3\")\n",
        "\n",
        "# Clean Data\n",
        "csv_data = clean_data(csv_data)\n",
        "excel_data = clean_data(excel_data)\n",
        "sql_data = clean_data(sql_data)\n",
        "\n",
        "# Merge Data\n",
        "final_dataset = merge_datasets([csv_data, excel_data, sql_data])\n",
        "\n",
        "# Save to CSV\n",
        "final_dataset.to_csv(\"standardized_train_schedule.csv\", index=False)\n",
        "\n",
        "print(\"ETL pipeline executed successfully. Standardized train schedule saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nUN1pBoRKQJ",
        "outputId": "dd9fdaa9-44ab-4e2a-8d45-e6eb569f4978"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.39)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: pymysql in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.12.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "ETL pipeline executed successfully. Standardized train schedule saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6p-s1rTfSX5U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}